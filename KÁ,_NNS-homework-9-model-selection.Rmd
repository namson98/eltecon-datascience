---
title: "Homework - Week 9 - Model Selection"
author: "Kovács Ádám József, Nguyen Nam Son"
date: "11/11/2020"
output: html_document
---

```{r setup, warning = FALSE, message = FALSE}

knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(out.width = '65%')
knitr::opts_chunk$set(fig.align = 'center')

library(data.table)
library(ggplot2)
library(magrittr)
library(glue)
library(purrr)
library(caret)
library(knitr)

wd <- file.path("~", "eltecon-datascience")
setwd(wd)

data <- fread("spam_clean.csv")
kable(head(
  data[, .(is_spam, message, nchar, nwords)]))

```

**Models**

```{r cm}

# Seperate train-test set
train_proportion <- 0.7
n <- nrow(data)
set.seed(1234)
train_index <- sample(1:n, floor(n*train_proportion))

data_train <- data[train_index,]
data_test <- data[-train_index,]

# model 1
model1 <- glm(
  is_spam ~ .,
  data = data_train[,c(1, 3:73)],
  family = binomial(link = "logit")
)

# model 2
model2 <- glm(
  is_spam ~ .,
  data = data_train[,c(1, 3:200)],
  family = binomial(link = "logit")
)

```

**Precision, Recall, and F1 scores**

```{r acc}

# Define measure of interest
calculateAccuracy <- function(predicted, actual) {
  predicted <- as.factor(predicted)
  actual <- as.factor(actual)
  precision <- posPredValue(predicted, actual, positive="1")
  recall <- sensitivity(predicted, actual, positive="1")
  F1 <- (2 * precision * recall) / (precision + recall) #weighted average of precision and recall
  return(F1)
}
```

**F1 of model 1 for train and test**

```{r acc1}

# Transform probabilities and calculate accuracy measures for train and test set
predicted_prob1_train <- predict.glm(model1, newdata = data_train, type = "response")
predicted_class1_train <- ifelse(predicted_prob1_train > 0.5, 1, 0)
model1_train_acc <- calculateAccuracy(data_train$is_spam, predicted_class1_train)

paste("The accuracy of the training set is:", scales::percent(model1_train_acc))

predicted_prob1 <- predict.glm(model1, newdata = data_test, type = "response")
predicted_class1 <- ifelse(predicted_prob1 > 0.5, 1, 0)
model1_test_acc <- calculateAccuracy(data_test$is_spam, predicted_class1)

paste("The accuracy of the test set is:", scales::percent(model1_test_acc))

```

**F1 of model 2 for train and test**

```{r acc2}

# Transform probabilities and calculate accuracy measures for train and test set
predicted_prob2_train <- predict.glm(model2, newdata = data_train, type = "response")
predicted_class2_train <- ifelse(predicted_prob2_train > 0.5, 1, 0)
model2_train_acc <- calculateAccuracy(data_train$is_spam, predicted_class2_train)

paste("The accuracy of the training set is:", scales::percent(model2_train_acc))

predicted_prob2 <- predict.glm(model2, newdata = data_test, type = "response")
predicted_class2 <- ifelse(predicted_prob2 > 0.5, 1, 0)
model2_test_acc <- calculateAccuracy(data_test$is_spam, predicted_class2)

paste("The accuracy of the test set is:", scales::percent(model2_test_acc))

```

**Cross validation**

```{r methods, warning=FALSE}

#creating folds for the 1st model
folds <- 5
n <- nrow(data)

set.seed(1234)
holdout <- split(sample(1:n), 1:folds)

CV_ACC <- map(holdout, ~{
    model <- glm(
        is_spam ~ .,
        data =  data[-.x, c(1, 3:73)],
        family = binomial(link = "logit")
    )
    pred <- predict(model, newdata = data[.x,], type = "response")
    predicted_class <- ifelse(pred > 0.5, 1, 0)
    calculateAccuracy(data[.x,is_spam], predicted_class)
})

paste("The mean accuracy of the 1st model after k-fold CV is:", scales::percent(mean(unlist(CV_ACC))))

#creating folds for the 2nd model
folds <- 5
n <- nrow(data)

set.seed(1234)
holdout <- split(sample(1:n), 1:folds)

CV_ACC <- map(holdout, ~{
    model <- glm(
        is_spam ~ .,
        data =  data[-.x, c(1, 3:200)],
        family = binomial(link = "logit")
    )
    pred <- predict(model, newdata = data[.x,], type = "response")
    predicted_class <- ifelse(pred > 0.5, 1, 0)
    calculateAccuracy(data[.x,is_spam], predicted_class)
})

paste("The mean accuracy of the 2nd model after k-fold CV is:", scales::percent(mean(unlist(CV_ACC))))

```
***
